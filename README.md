# ü§ñ SmolAgents + Streamlit Demo

A tiny and complete end-to-end project demonstrating agentic AI with tool use:

- **smolagents** for agent logic and tool orchestration.
- **Hugging Face Inference API** for a free, hosted LLM.
- **Streamlit** for a clean web chat interface.

The agent runs on the open model:

`Qwen/Qwen2.5-7B-Instruct`(free tier)

It can intelligently decide when to use Python tools such as:

- `get_time(timezone)` ‚Äì Get current time in any timezone.
- `word_count(text)` ‚Äì Count words in a string.

This is a minimal production-ready "AI app" you can run locally in minutes, plus an interactive terminal interface for testing!

## üìÅ Project Structure

```bash
smol_streamlit_agent/
‚îú‚îÄ‚îÄ .env                    # Your HF token (ignored by git)
‚îú‚îÄ‚îÄ .gitignore              # Files excluded from version control
‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îú‚îÄ‚îÄ README.md               # This file
‚îÇ
‚îú‚îÄ‚îÄ tools.py                # Custom Python tools for the agent
‚îú‚îÄ‚îÄ agent.py                # Agent construction (smolagents + model)
‚îú‚îÄ‚îÄ app.py                  # Streamlit web UI (chat interface)
‚îÇ
‚îî‚îÄ‚îÄ test/                   # Testing suite
    ‚îú‚îÄ‚îÄ test_tools.py       # Test tools directly (fastest)
    ‚îú‚îÄ‚îÄ test_agent.py       # Test agent with predefined questions
    ‚îú‚îÄ‚îÄ interactive_test.py # Terminal chat interface
    ‚îî‚îÄ‚îÄ run_all_tests.py    # Run all tests in sequence
```

## üöÄ Quick Start

### 1. Clone and Setup

```bash
# Create virtual environment
python -m venv .venv

# Activate it
source .venv/bin/activate   # Linux/Mac
.venv\Scripts\activate      # Windows
```

### 2. Install dependencies

```bash
pip install -U pip
pip install -r requirements.txt
```

### 3. Create a Hugging Face token

- Go to Hugging Face ‚Üí Settings ‚Üí Access Tokens.
- Create a Fine-grained token with:
  - Inference ‚Üí Make calls to Inference Providers.
  - Repositories ‚Üí Read access to public gated repos you can access.

Create an `.env` file and add your token:

```bash
HUGGINGFACEHUB_API_TOKEN=hf_your_token_here
```

## üß™ Testing (Before running the app)

### 1. Test Tools (Fastest)

```bash
# Create virtual environment
python -m venv .venv

# Activate it
source .venv/bin/activate   # Linux/Mac
.venv\Scripts\activate      # Windows
```

### 2. Test Agent

```bash
python test/test_agent.py
```

Runs predefined test cases to verify agent functionality.

### 3. Interactive Terminal Chat

```bash
python test/interactive_test.py
```

Chat with your agent directly in the terminal:

```
ü§ñ INTERACTIVE AGENT TEST
üì¶ Model: Qwen/Qwen2.5-7B-Instruct
üí° Type your questions and press Enter

You: What time is it in Berlin?
ü§ñ Agent (took 3.2s): The current time in Berlin is 2024-01-28T15:30:45+01:00

You: quit
üëã Goodbye!
```

### Run All Tests at once

```bash
python test/run_all_tests.py
```

## üåê Run the App

```bash
streamlit run app.py
```

Open the local URL shown in your terminal (typically http://localhost:8501).

Try prompts like:

- "What time is it in Tokyo?"
- "Count the words in: 'agents are loops with ambition'"
- "What time is it in Berlin and New York?"
- "Write a haiku about black holes, then count its words"

## ‚öôÔ∏è Configuration

### Change the Model

Edit `agent.py` to use a different model:

```python
# Current model (recommended)
MODEL_ID = "Qwen/Qwen2.5-7B-Instruct"

# Alternatives (all free):
# MODEL_ID = "Qwen/Qwen2.5-3B-Instruct"      # Faster, less capable
# MODEL_ID = "Qwen/Qwen2.5-14B-Instruct"     # Slower, more capable
# MODEL_ID = "meta-llama/Llama-3.2-3B-Instruct"
```

### Add New Tools

Add to `tools.py`:

```python
from smolagents import tool

@tool
def your_new_tool(param: str) -> str:
    """
    Description of what your tool does.

    Args:
        param: Description of the parameter

    Returns:
        Description of what it returns
    """
    # Your implementation
    return result
```

Then register it in `agent.py`:

```python
from tools import get_time, word_count, your_new_tool

agent = CodeAgent(
    tools=[get_time, word_count, your_new_tool],
    # ...
)
```

## üéì Learning Resources

- [smolagents Documentation](https://github.com/huggingface/smolagents)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Hugging Face Inference API](https://huggingface.co/docs/api-inference)
- [Building AI Agents Guide](https://huggingface.co/blog/smolagents)

## üìù Notes

- The **Hugging Face free tier** has rate limits and occasional cold starts.
- `Qwen 2.5 7B` provides the best balance of speed and capability for free.
- This project is intentionally minimal: it's a **learning scaffold**showing how agents, tools, models, and UI fit together.
- All code is production-ready with proper error handling and testing.

## Next Steps

1. **Add more tools** (weather API, calculator, web search)
2. **Integrate with external APIs** (news, stocks, etc.)
3. **Deploy to cloud** (Streamlit Cloud, HF Spaces)
4. **Add conversation memory** for multi-turn dialogues
5. **Implement RAG** (Retrieval Augmented Generation)
